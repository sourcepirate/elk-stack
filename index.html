<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>ELK training</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<H2>Introduction to log analytics with ELK</H2>
					<center>
						<H3> About Me</H3>
						<ul>
							<li>Sathya Narrayanan Balaji</li>
							<li>@sourcepirate at twitter</li>
							<li>github.com/<i>sourcepirate</i></li>
						</ul>
					</center>
				</section>
				<section data-markdown>
					<textarea data-template>
						## Agenda
				
						* Introduction to data driven decisions.
						* Advantages of data driven decisions.
						* Breif view on log analytics.
						* Managing Analytics infrastructure.

					</textarea>
				</section>
				<section data-markdown>
						<textarea data-template>
							## Introduction to data driven decisions.

							![decisions](https://blog.intercom.com/wp-content/uploads/2011/11/Decisions.jpg)
	
						</textarea>
				</section>
				<section data-markdown>
						<textarea data-template>

							## Advantages

							* Measurable results.
							* Adaptability.
							* No ego.
							* Less people involved in decision making.

						</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						## Brief view on log analytics

						* What is log analytics ?
						* Why is it used ?
						* Why should i care ?
					
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						## Process of Log Analytics

						![Log analytics](https://cdn-images-1.medium.com/max/1600/0*g5z_taTCLF-lPXwA.png)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						## Components of log analytics infrastructure

						![Log Components](https://image.slidesharecdn.com/theelkstack-gettoknowlogs-igorrudyk-150514141113-lva1-app6891/95/the-elk-stack-get-to-know-logs-17-638.jpg?cb=1431613304)
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						## Log Shipper

						Ships log from a process or a file to other host or broker in structured format.

						Examples:
						  * fluentd
						  * logstash
						  * filebeat
						
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						## Log indexer
						
						Adds appropriate tags and component values into the log message.

						Examples:
						  * logstash

					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						## Search Engine

						Indexes all the json log messages.

						Examples:
						  * elasticsearch
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						## Visulalizer

						Visualize the data in form of graphs and charts.

						Examples:
						  * kibana
						  * grafana
						  * splunk

					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
					## ElasticSearch

					Elasticsearch is a search engine based on Lucene. It provides a distributed, multitenant-capable 
					full-text search engine with an HTTP web interface and schema-free JSON documents.

					https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html

					Rest API's:
					
					http://elasticsearch-cheatsheet.jolicode.com

					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						## Logstash

						* It's a data ingestion tool. Ingests data from multiple sources.
						* A Logstash pipeline has two required elements, input and output, and one optional element, filter. 
						  The input plugins consume data from a source, the filter plugins modify the data as you specify,
						   and the output plugins write the data to a destination.

						```
						bin/logstash -e 'input { stdin { } } output { stdout {} }'
						```

					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						## Typical Logstash Config

						```
						input { stdin { } }

							filter {
							grok {
								match => { "message" => "%{COMBINEDAPACHELOG}" }
							}
							date {
								match => [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]
							}
							}

							output {
							elasticsearch { hosts => ["localhost:9200"] }
							stdout { codec => rubydebug }
							}
						```
					</textarea>
				</section>
				<section data-markdown>
				  <textarea data-template>
				     ## Demo Time
				  </textarea>
				</section>
				<section data-markdown>
				  <textarea data-template>
				     ## Questions ?
				  </textarea>
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			Reveal.initialize({
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
